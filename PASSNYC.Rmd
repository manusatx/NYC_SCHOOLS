---
title: "PASSNYC MAIN"
author: "Manoranjan Kumar"
date: "7/23/2018"
output:
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
getwd()
setwd("~/Desktop/PASSNYC")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy=TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache=FALSE)
hook1 <- function(x){ gsub("```\n*```r*\n*", "", x) }
hook3 <- function(x){ gsub("```\n+```\n", "", x) }
hook3 <- function(x){ gsub("```\n+```\n", "", gsub("```\n*```r*\n*", "", x)) }
hook4 <- function(x){ gsub("```\n+```\n", "",  gsub("message", "", x)) }
knitr::knit_hooks$set(document = hook4)
```

```{r}
#Read the saved scv back again
SchoolMain <- read.csv("https://raw.githubusercontent.com/manusatx/NYC_SCHOOLS/master/SchoolMain.csv")
dim(SchoolMain)
#data exploration for predictors
#Remove ID and name and other Identificable varaibles by looking at the data - 27 variables removed
SchoolMain <- subset(SchoolMain, select=-c(X, District, New.,Adjusted.Grade, GEOID, Other.Location.Code.in.LCGMS,SchoolGEOID, School.Name,SED.Code,Location.Code,Latitude,Longitude,Address..Full.,City,Zip,Grades,Grade.Low,Grade.High, Rigorous.Instruction.Rating,Collaborative.Teachers.Rating,Supportive.Environment.Rating,Effective.School.Leadership.Rating,Strong.Family.Community.Ties.Rating,Trust.Rating,Student.Achievement.Rating))
dim(SchoolMain)
#Convert community to 1 / 0 vs Yes No
SchoolMain$Community.School.<- ifelse(SchoolMain$Community.School.=="Yes", 1, 0)

#Convert all columns to numeric
SchoolMain <- as.data.frame(lapply(SchoolMain, function(x) as.numeric(as.character(x))))

#Make Community.School as factor
SchoolMain$Community.School. <- as.factor(SchoolMain$Community.School.)

#Merge the ELA and maths score to form one response variable column
SchoolMain$Average_Proficiency <- (SchoolMain$Average.ELA.Proficiency + SchoolMain$Average.Math.Proficiency)/2
SchoolMain <- subset(SchoolMain, select=-c(Average.ELA.Proficiency, Average.Math.Proficiency))

# Missing values
summary(SchoolMain)

# check only for response variable Yield 
nrow(SchoolMain[is.na(SchoolMain$Average_Proficiency),])
print('There are 55 rows with some missing data')

#Check Distribution of response variable
library(AppliedPredictiveModeling)
library(lattice)
transparentTheme(pchSize = 1, trans = .7)
mean.values=mean(SchoolMain$Average_Proficiency)
histogram(~Average_Proficiency, data = SchoolMain, xlab = "Average_Proficiency", 
          panel = function(x,...) {
            panel.histogram(x, ...) 
            panel.abline(v=mean.values, col.line="red", identifier = "abline" ,lty = 4)
            })

#Remove 55 rows from data where response variable is NULL
SchoolMain_NA_Resp <- SchoolMain[is.na(SchoolMain$Average_Proficiency),]
SchoolMain <- SchoolMain[!is.na(SchoolMain$Average_Proficiency),]

#see predictors data with missing values
nrow(SchoolMain[rowSums(is.na(subset(SchoolMain, select = - Average_Proficiency))) > 0,])
print('There are 394 rows with some missing data')

```

```{r}
#Use Knn imputation to preprocess the data
library(caret)
SchoolMain_prepro_index <- preProcess(subset(SchoolMain, select = -Average_Proficiency), 
                                method=c("BoxCox", "knnImpute"))
SchoolMain_new <- predict(SchoolMain_prepro_index, SchoolMain)

#see predictors data with missing values after imputation
nrow(SchoolMain_new[rowSums(is.na(subset(SchoolMain_new, select = - Average_Proficiency))) > 0,])
print('There are 0 rows with some missing data after knn imputation')

#Create a df with predictors only and without the factor columns has 24 columns
SchoolMain_new_numeric <- SchoolMain_new[,sapply(SchoolMain_new[, !names(SchoolMain_new) %in% c("Average_Proficiency")], is.numeric)]

#df with factor and response has 2 columns 
SchoolMain_fctr_resp <- subset(SchoolMain_new, select=c(Community.School.,Average_Proficiency))
```

```{r}
#check for near zero variance variables
library(caret)
rm_SchoolMain_cols <- nearZeroVar(SchoolMain_new)
rm_SchoolMain_cols
print('there is no columns with near zero variance')

#Check the data numeric volumns for correlation for 24 predictors
library(caret)
SchoolMaincorr = cor(SchoolMain_new_numeric)
corrplot::corrplot(SchoolMaincorr, order = "hclust", addrect = 9, method = "circle",  tl.cex = 0.6)

#library(ggcorrplot)
#ggcorrplot(SchoolMaincorr ,hc.order = TRUE, method = c("square"),tl.cex = 7, show.diag = FALSE, ggtheme = ggplot2::theme_minimal)

#Check for correlated varaibles and remove highly correlated predictors
SchoolMaincorrpp <- findCorrelation(SchoolMaincorr, cutoff = 0.8)
SchoolMain_no_cor <- SchoolMain_new_numeric[, -SchoolMaincorrpp]
dim(SchoolMain_new_numeric)
dim(SchoolMain_no_cor)
print('From the continuous variables 7 correlated predictor variables were removed with correlation check and now we have 24-7 =  17 predictor variables')

#PCA
SchoolMain.pca <- prcomp(SchoolMain_new_numeric, center = TRUE, scale. = TRUE)
s <- summary(SchoolMain.pca)
#Plot cumulative variance Principal components
plot(1:24, s$importance[3,], type = "b")
print('PC1, PC2 till PC10 explain 90% of variance cumulatively as seen from the summary')
#Plot the resultant Principal components
#biplot(SchoolMain.pca, scale = 1, cex = 0.6)

#with removed highly correlated variables datset is now having 19 columns and 1217 rows
SchoolMain_reducedcorr <- cbind(SchoolMain_no_cor,SchoolMain_fctr_resp)
dim(SchoolMain_reducedcorr)
```

```{r}
#variable clustering and dimesnionality reduction
#calculate R2 Ratio for each variable in each cluster. We will then select variable with minimum 1-R2 ratio in each cluster as cluster representative
r2clusterfun <- function(inputdf,insim, numcuttree) {
library(Hmisc)
varclus.inputdf <- varclus(data.matrix(inputdf), similarity=insim)
plot(varclus.inputdf)
# Below is hclust object
hclust.inputdf<- varclus.inputdf$hclust 
#plot the 10 clusters by cut
plot(hclust.inputdf)
rect.hclust(hclust.inputdf, k=numcuttree, border="red")
#Cut the above into 10 clusters and assign name to data frame
groups.inputdf <- as.data.frame(cutree(hclust.inputdf, k=numcuttree))
library(data.table)
groups.inputdf <- as.data.frame(setDT(groups.inputdf, keep.rownames = TRUE)[])
colnames(groups.inputdf) <- c("var","clusternum")
groups.inputdf$ID <- seq.int(nrow(groups.inputdf))
groups.inputdf$ID <- as.character (groups.inputdf$ID)
groups.inputdf.index.list <- as.list(as.matrix(by(groups.inputdf$ID ,groups.inputdf$clusternum,function(x)return(as.numeric(as.character(x))))))
#Check for index lists  > 1
index.list <- groups.inputdf.index.list[sapply(groups.inputdf.index.list, length) > 1]
index.list.1 <- groups.inputdf.index.list[sapply(groups.inputdf.index.list, length) == 1]
# Disimilarity matrix (1-r^2) using Pearson
cor.inputdf<-cor(inputdf, method = insim)
cormatrix<-round((1-(cor.inputdf)^2), 3)
# cormatrix is dissimilarity matrix
# Dissimalrity (1-r^2) between elements of a cluster and the other elements in its own cluster
	h<-function(index){
		temp<-cormatrix[index,index]
		diag(temp)<-NA
		apply(temp,1,min,na.rm=T)
	}
	numer<-lapply(index.list,h)
# Dissimalrity (1-r^2) between elements of each cluster and other clusters
	g<-function(index){
		apply(cormatrix[-index,index],2,min)
	}
	denom<-lapply(index.list,g)
# Find the minimum r^2 ratio
	i<-function(index){
	which.min(numer[[index]]/denom[[index]])
	}
	apply(as.matrix(1:length(index.list)),1,i)
	# get the index of each cluster lowest r2 element	
	min_r2_index <- as.data.frame(apply(as.matrix(1:length(index.list)),1,i))
	colnames(min_r2_index) <- c("min_r2_idx")
  min_r2_index$id <- seq.int(nrow(min_r2_index))
  
  print('The 10 variables with the lowest r2 ratio in each cluster using lowest rsq ratio is :')
  subsetvar <- matrix(NA, nrow = length(index.list), ncol = 1)
for ( i in min_r2_index[,"id"]) {
	  j <-  min_r2_index[i,"min_r2_idx"]
	  i_idx <- index.list[[i]][j]
	  subsetvar[i] <- as.character(groups.inputdf[groups.inputdf$ID == i_idx,][,"var"])
}
  #get columns for clusters which had only one variable
  index.list.1.df <- as.data.frame(unlist(index.list.1))
  colnames(index.list.1.df) <- c("col_idx")
  index.list.1.df$id <- seq.int(nrow(index.list.1.df))
  subsetvarone <- matrix(NA, nrow = length(index.list.1), ncol = 1)
  for ( i in index.list.1.df[,"id"]) {
   i_idx <- index.list.1.df[i,"col_idx"]
	  subsetvarone[i] <- as.character(groups.inputdf[groups.inputdf$ID == i_idx,][,"var"])
}
  allsubvars <- rbind(subsetvar,subsetvarone)
	return (allsubvars)
}
#Apply function r2clusterfun use cut = 10 as seen from pca around PC1 to PC10 explian 90% of variance
SchoolMain_subset<- r2clusterfun(SchoolMain_new_numeric,insim='spearman',numcuttree=10)
# These are the predictor variables selected after numcuttree = 10 and min rsq ratio selection.
print(SchoolMain_subset[,1])
print('correlation between the above 10 elements is')
# Reduced dataset with only 10 variables is SchoolMain_reduced
SchoolMain_reduced_numeric <- SchoolMain_new_numeric[,c(SchoolMain_subset)]
SchoolMain_subset_corr <-round(cor(SchoolMain_reduced_numeric, method = c("spearman")),2)
#SchoolMain_subset_corr
print('The subset of variables selected show no or very low correlation to each other.')

#Check the data numeric volumns for correlation
corrplot::corrplot(SchoolMain_subset_corr, order = "hclust", addrect = 4, method = "circle",  tl.cex = 0.6)

#Create a data set with reduced predictor variables with 
SchoolMain_reduced <- cbind(SchoolMain_reduced_numeric,SchoolMain_fctr_resp)
dim(SchoolMain_reduced)

```


```{r}
#split the unreduced data into train and test
set.seed(1000)
train.school.index <- createDataPartition(y = SchoolMain_reducedcorr$Average_Proficiency, p = 0.85, list = FALSE)
trainschool <- SchoolMain_reducedcorr[train.school.index, ]
testschool <- SchoolMain_reducedcorr[-train.school.index, ]
dim(trainschool)
dim(testschool)
```

```{r}
#split the reduced data into train and test
set.seed(1000)
train.reduced.school.index <- createDataPartition(y = SchoolMain_reduced$Average_Proficiency, p = 0.85, list = FALSE)
trainreducedschool <- SchoolMain_reduced[train.reduced.school.index, ]
testreducedschool <- SchoolMain_reduced[-train.reduced.school.index, ]
dim(trainreducedschool)
dim(testreducedschool)
```

```{r}
#Run the LM model
set.seed(1000)
lm_school_model = train( Average_Proficiency ~., data = trainschool,method="lm",
                         tuneLength = 10,
                   preProcess=c("center","scale"), 
                   trControl=trainControl(method="repeatedcv", number = 10) )
summary(lm_school_model)

#Run the LM model with pca
set.seed(1000)
lm_pca_school_model = train( Average_Proficiency ~., data = trainschool,method="lm",
                             tuneLength = 10,
                   preProcess=c("pca"), 
                   trControl=trainControl(method="repeatedcv", number = 10) )
summary(lm_pca_school_model)
```

```{r}
set.seed(1000)
#Run the PLS model
pls_school_model = train(Average_Proficiency ~., data = trainschool,method="pls",
                         tuneLength = 10,
                   preProcess=c("center","scale"), 
                   trControl=trainControl(method="repeatedcv", number = 10) )
#summary(pls_school_model)
#head(pls_school_model$results)

plot(pls_school_model,metric="Rsquared")
library(pls)
pls_school_imp <- varImp(pls_school_model, scale = FALSE)
plot(pls_school_imp, top=10, scales = list(y = list(cex = 0.8)))
school_order_pls_index <- order(abs(pls_school_imp$importance),decreasing=TRUE)
top_pls_vars = rownames(pls_school_imp$importance)[school_order_pls_index[c(1:6)]]
top_pls_vars

#Explore the univariate relationships of top 5 variables with Yield using featureplot
featurePlot(trainschool[, top_pls_vars],
            trainschool$Average_Proficiency,
            plot = "scatter",
            between = list(x = 1, y = 1),
            type = c("g", "p", "smooth"),
            layout = c(3,1),
            labels = rep("", 2),
            warn = FALSE
            )
```


```{r}
set.seed(1000)
#Run the PCR model
pcr_school_model = train( Average_Proficiency ~., data = trainschool,method="pcr",
                          tuneLength = 10,
                   preProcess=c("center","scale"), 
                   trControl=trainControl(method="repeatedcv", number = 10) )
summary(pcr_school_model)
head(pcr_school_model$results)

plot(pcr_school_model,metric="Rsquared")

pcr_school_imp = varImp(pcr_school_model, scale = FALSE)
plot(pcr_school_imp, top=10, scales = list(y = list(cex = 0.8)))
school_order_pcr_index <- order(abs(pcr_school_imp$importance),decreasing=TRUE)
top_pcr_vars = rownames(pcr_school_imp$importance)[school_order_pcr_index[c(1:6)]]
top_pcr_vars

#Explore the univariate relationships of top 5 variables with Yield using featureplot
featurePlot(trainschool[, top_pcr_vars],
            trainschool$Average_Proficiency,
            plot = "scatter",
            between = list(x = 1, y = 1),
            type = c("g", "p", "smooth"),
            layout = c(3,1),
            labels = rep("", 2),
            warn = FALSE
            )

```

```{r}
#Run the SVM model
set.seed(1000)
svm_school_model = train( Average_Proficiency ~., data = trainschool,method="svmLinear",
                          tuneLength = 10,
                   trControl=trainControl(method="repeatedcv", number = 10),
                  preProc = c("center", "scale"))
#summary(svm_school_model)
head(svm_school_model$results)
```

```{r}
#Run the random forest model
set.seed(1000)
rf_school_model = train( Average_Proficiency ~., data = trainschool,method="rf",
                         tuneLength = 10,
                         trControl=trainControl(method="repeatedcv", number = 10),
                         preProc = c("center", "scale"))
summary(rf_school_model)
head(rf_school_model$results)
```

```{r}
# Ridge Regression Model
set.seed(1000)
ridge_school_model <- train(Average_Proficiency ~., data = trainschool, method = "ridge",
                            trControl =  trainControl(method = "repeatedcv", repeats = 10), 
                   preProc = c("center", "scale"), tuneLength = 5)
#summary(ridge_school_model)

plot(ridge_school_model,metric="Rsquared")
```

```{r}
#LASSO Model
set.seed(1000)
lasso_school_model <- train(Average_Proficiency ~., data = trainschool, method = "lasso", 
                     trControl = trainControl(method = "repeatedcv", repeats = 10), 
                     preProc = c("center", "scale"), tuneLength = 5) 
#summary(lasso_school_model)
plot(ridge_school_model,metric="Rsquared")
```

```{r}
#ENET Model (ELastic net Regression)
set.seed(1000)
library(elasticnet)
enet_school_model <- train(Average_Proficiency ~., data = trainschool, method = "enet", 
                    trControl = trainControl(method = "repeatedcv", repeats = 10), 
                    preProc = c("center", "scale"), tuneLength = 5) 
#summary(enet_school_model)
plot(enet_school_model,metric="Rsquared")
```

```{r}
# Compare the model, this works only when trcontrol or sampling method is same in all the models used.
resamp_school_1 = resamples( list(lm=lm_school_model,lm.pca=lm_pca_school_model,pcr=pcr_school_model,
                                  rf=rf_school_model,svm=svm_school_model,
                                  pls=pls_school_model) )
print(summary(resamp_school_1))

resamp_school = resamples( list(ridge=ridge_school_model,lasso=lasso_school_model,enet=enet_school_model) )
print( summary(resamp_school) )
```

```{r}
print('RMSE an R2 for train data for these models:-')
Average_Proficiency_lm_hat = predict( lm_school_model, newdata=subset(trainschool, select=-c(Average_Proficiency)) )
r2_lm = cor(Average_Proficiency_lm_hat,trainschool$Average_Proficiency,method="pearson")^2
rmse_lm = sqrt( mean( (Average_Proficiency_lm_hat-trainschool$Average_Proficiency)^2 ) )

Average_Proficiency_pls_hat = predict( pls_school_model, newdata=subset(trainschool, select=-c(Average_Proficiency)) )
r2_pls = cor(Average_Proficiency_pls_hat,trainschool$Average_Proficiency,method="pearson")^2
rmse_pls = sqrt( mean( (Average_Proficiency_pls_hat-trainschool$Average_Proficiency)^2 ) )

Average_Proficiency_pcr_hat = predict( pcr_school_model, newdata=subset(trainschool, select=-c(Average_Proficiency)) )
r2_pcr = cor(Average_Proficiency_pcr_hat,trainschool$Average_Proficiency,method="pearson")^2
rmse_pcr = sqrt( mean( (Average_Proficiency_pcr_hat-trainschool$Average_Proficiency)^2 ) )

Average_Proficiency_rf_hat = predict( rf_school_model, newdata=subset(trainschool, select=-c(Average_Proficiency)) )
r2_rf = cor(Average_Proficiency_rf_hat,trainschool$Average_Proficiency,method="pearson")^2
rmse_rf = sqrt( mean( (Average_Proficiency_rf_hat-trainschool$Average_Proficiency)^2 ) )

Average_Proficiency_svm_hat = predict( svm_school_model, newdata=subset(trainschool, select=-c(Average_Proficiency)) )
r2_svm = cor(Average_Proficiency_svm_hat,trainschool$Average_Proficiency,method="pearson")^2
rmse_svm = sqrt( mean( (Average_Proficiency_svm_hat-trainschool$Average_Proficiency)^2 ) )

Average_Proficiency_ridge_hat = predict( ridge_school_model, newdata=subset(trainschool, select=-c(Average_Proficiency)) )
r2_ridge = cor(Average_Proficiency_ridge_hat,trainschool$Average_Proficiency,method="pearson")^2
rmse_ridge = sqrt( mean( (Average_Proficiency_ridge_hat-trainschool$Average_Proficiency)^2 ) )

Average_Proficiency_lasso_hat = predict( lasso_school_model, newdata=subset(trainschool, select=-c(Average_Proficiency)) )
r2_lasso = cor(Average_Proficiency_lasso_hat,trainschool$Average_Proficiency,method="pearson")^2
rmse_lasso = sqrt( mean( (Average_Proficiency_lasso_hat-trainschool$Average_Proficiency)^2 ) )

train.rmse.table <- rbind(rmse_lm,rmse_pls,rmse_pcr,rmse_rf,rmse_svm,rmse_ridge,rmse_lasso)
train.rmse.table
train.r2.table <- rbind(r2_lm,r2_pls,r2_pcr,r2_rf,r2_svm,r2_ridge,r2_lasso)
train.r2.table
```


```{r}
print('RMSE an R2 for test data for these models:-')
Average_Proficiency_lm_hat = predict( lm_school_model, newdata=subset(testschool, select=-c(Average_Proficiency)) )
r2_lm = cor(Average_Proficiency_lm_hat,testschool$Average_Proficiency,method="pearson")^2
rmse_lm = sqrt( mean( (Average_Proficiency_lm_hat-testschool$Average_Proficiency)^2 ) )

Average_Proficiency_pls_hat = predict( pls_school_model, newdata=subset(testschool, select=-c(Average_Proficiency)) )
r2_pls = cor(Average_Proficiency_pls_hat,testschool$Average_Proficiency,method="pearson")^2
rmse_pls = sqrt( mean( (Average_Proficiency_pls_hat-testschool$Average_Proficiency)^2 ) )

Average_Proficiency_pcr_hat = predict( pcr_school_model, newdata=subset(testschool, select=-c(Average_Proficiency)) )
r2_pcr = cor(Average_Proficiency_pcr_hat,testschool$Average_Proficiency,method="pearson")^2
rmse_pcr = sqrt( mean( (Average_Proficiency_pcr_hat-testschool$Average_Proficiency)^2 ) )

Average_Proficiency_rf_hat = predict( rf_school_model, newdata=subset(testschool, select=-c(Average_Proficiency)) )
r2_rf = cor(Average_Proficiency_rf_hat,testschool$Average_Proficiency,method="pearson")^2
rmse_rf = sqrt( mean( (Average_Proficiency_rf_hat-testschool$Average_Proficiency)^2 ) )

Average_Proficiency_svm_hat = predict( svm_school_model, newdata=subset(testschool, select=-c(Average_Proficiency)) )
r2_svm = cor(Average_Proficiency_svm_hat,testschool$Average_Proficiency,method="pearson")^2
rmse_svm = sqrt( mean( (Average_Proficiency_svm_hat-testschool$Average_Proficiency)^2 ) )

Average_Proficiency_ridge_hat = predict( ridge_school_model, newdata=subset(testschool, select=-c(Average_Proficiency)) )
r2_ridge = cor(Average_Proficiency_ridge_hat,testschool$Average_Proficiency,method="pearson")^2
rmse_ridge = sqrt( mean( (Average_Proficiency_ridge_hat-testschool$Average_Proficiency)^2 ) )

Average_Proficiency_lasso_hat = predict( lasso_school_model, newdata=subset(testschool, select=-c(Average_Proficiency)) )
r2_lasso = cor(Average_Proficiency_lasso_hat,testschool$Average_Proficiency,method="pearson")^2
rmse_lasso = sqrt( mean( (Average_Proficiency_lasso_hat-testschool$Average_Proficiency)^2 ) )

test.rmse.table <- rbind(rmse_lm,rmse_pls,rmse_pcr,rmse_rf,rmse_svm,rmse_ridge,rmse_lasso)
test.rmse.table
test.r2.table <- rbind(r2_lm,r2_pls,r2_pcr,r2_rf,r2_svm,r2_ridge,r2_lasso)
test.r2.table
```

```{r}
#Run Models on reduced 10 variables after rsq ratio based reduction dataset
#Run the PLS model
set.seed(10)
pls_school_reduced_model = train( Average_Proficiency ~., data = trainreducedschool,method="pls",
                   tuneLength=10, 
                   preProcess=c("center","scale"), 
                   trControl=trainControl(method="repeatedcv", number = 10) )
summary(pls_school_reduced_model)
head(pls_school_reduced_model$results)

plot(pls_school_reduced_model,metric="Rsquared")
library(pls)
pls_school_reduced_imp <- varImp(pls_school_reduced_model, scale = FALSE)
plot(pls_school_reduced_imp, top=15, scales = list(y = list(cex = 0.8)))
reduced_school_order_pls_index <- order(abs(pls_school_reduced_imp$importance),decreasing=TRUE)
reduced_top_pls_vars = rownames(pls_school_reduced_imp$importance)[reduced_school_order_pls_index[c(1:5)]]
reduced_top_pls_vars

#Explore the univariate relationships of top 5 variables with Yield using featureplot
featurePlot(trainreducedschool[, reduced_top_pls_vars],
            trainreducedschool$Average_Proficiency,
            plot = "scatter",
            between = list(x = 1, y = 1),
            type = c("g", "p", "smooth"),
            layout = c(3,1),
            labels = rep("", 2),
            warn = FALSE
            )
```

```{r}
Average_Proficiency_pls_reduced_hat = predict( pls_school_reduced_model, newdata=subset(trainreducedschool, select=-c(Average_Proficiency)) )
r2_train_pls = cor(Average_Proficiency_pls_reduced_hat,trainreducedschool$Average_Proficiency,method="pearson")^2
r2_train_pls
rmse_train_pls = sqrt( mean( (Average_Proficiency_pls_reduced_hat-trainreducedschool$Average_Proficiency)^2 ) )
rmse_train_pls
```

```{r}
Average_Proficiency_pls_reduced_hat = predict( pls_school_reduced_model, newdata=subset(testreducedschool, select=-c(Average_Proficiency)) )
r2_test_pls = cor(Average_Proficiency_pls_reduced_hat,testreducedschool$Average_Proficiency,method="pearson")^2
r2_test_pls
rmse_test_pls = sqrt( mean( (Average_Proficiency_pls_reduced_hat-testreducedschool$Average_Proficiency)^2 ) )
rmse_test_pls
```